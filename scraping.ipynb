{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#urls to be scraped\n",
    "urls = {('Men','100 m'):'http://www.alltime-athletics.com/m_100ok.htm',\n",
    "       ('Men','200 m'):'http://www.alltime-athletics.com/m_200ok.htm',\n",
    "       ('Men','400 m'):'http://www.alltime-athletics.com/m_400ok.htm',\n",
    "       ('Men','800 m'):'http://www.alltime-athletics.com/m_800ok.htm',\n",
    "       ('Men','1500 m'):'http://www.alltime-athletics.com/m_1500ok.htm',\n",
    "       ('Men','5000 m'):'http://www.alltime-athletics.com/m_5000ok.htm',\n",
    "       ('Men','10,000 m'):'http://www.alltime-athletics.com/m_10kok.htm',\n",
    "       ('Men','Half marathon'):'http://www.alltime-athletics.com/mhmaraok.htm',\n",
    "       ('Men','Marathon'):'http://www.alltime-athletics.com/mmaraok.htm',\n",
    "       ('Women','100 m'):'http://www.alltime-athletics.com/w_100ok.htm',\n",
    "       ('Women','200 m'):'http://www.alltime-athletics.com/w_200ok.htm',\n",
    "       ('Women','400 m'):'http://www.alltime-athletics.com/w_400ok.htm',\n",
    "       ('Women','800 m'):'http://www.alltime-athletics.com/w_800ok.htm',\n",
    "       ('Women','1500 m'):'http://www.alltime-athletics.com/w_1500ok.htm',\n",
    "       ('Women','5000 m'):'http://www.alltime-athletics.com/w_5000ok.htm',\n",
    "       ('Women','10,000 m'):'http://www.alltime-athletics.com/w_10kok.htm',\n",
    "       ('Women','Half marathon'):'http://www.alltime-athletics.com/whmaraok.htm',\n",
    "       ('Women','Marathon'):'http://www.alltime-athletics.com/wmaraok.htm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to format all the times the same way\n",
    "def full_time(time):\n",
    "    result = time\n",
    "    #add zeros for hours and minutes\n",
    "    if(time.count(':')==0):\n",
    "        result = '0:0:'+time\n",
    "    elif(time.count(':')==1):\n",
    "        minutes = int(re.match(r'[\\d]+',time).group(0))\n",
    "        #convert 61:00 to 1:01:00\n",
    "        if(minutes>59):\n",
    "            result = '1:'+str(minutes-60)+time[2:]\n",
    "        else:\n",
    "            result = '0:'+time\n",
    "    #add zeros for tenths of second\n",
    "    if(result.count('.')==0):\n",
    "        result = result+'.0'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_df(key):\n",
    "    url = urls[key]\n",
    "    \n",
    "    #scrape the webpage\n",
    "    page = urllib2.urlopen(url)\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    data = str(soup.pre)\n",
    "    \n",
    "    lists = [re.split(r'\\s\\s+',line)[1:] for line in data.split('\\r\\n')]\n",
    "    #compute number of columns\n",
    "    max_len = len(max(lists, key=len))\n",
    "    \n",
    "    #ignore irrelevant rows\n",
    "    lists_clean = [line for line in lists if len(line)==max_len]\n",
    "    \n",
    "    #removed wind information if it exists and select the top 1000 performances\n",
    "    if max_len == 9:\n",
    "        lists_top = [line[:2]+line[3:] for line in lists_clean if int(line[0])<= 1000]\n",
    "    else:\n",
    "        lists_top = [line for line in lists_clean if int(line[0])<= 1000]\n",
    "    array = np.asarray(lists_top)\n",
    "    \n",
    "    df = pd.DataFrame(data = array, \n",
    "                  columns=['Rank','Time','Name','Country','Date of Birth','Place','City','Date'])\n",
    "\n",
    "    #clean time, dates, etc\n",
    "    df['Time'] = df['Time'].apply(lambda x: full_time(re.match(r'[\\d.:]+',x).group(0)))\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S.%f').dt.time\n",
    "    df['Date'] = df['Date'].apply(lambda x: re.match(r'[\\d.:]+',x).group(0))\n",
    "    df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
    "    df['Place'] = df['Place'].apply(lambda x: re.match(r'\\d+',x).group(0) if bool(re.match(r'\\d+',x)) else np.nan)\n",
    "    df['Date of Birth'] = df['Date of Birth'].apply(lambda x: '01.01.'+x if x.count('.')==0 else x)\n",
    "    df['Date of Birth'] = df['Date of Birth'].apply(lambda x: x[:-2]+'20'+x[-2:] if int(x[-2:]<40) else x[:-2]+'19'+x[-2:])\n",
    "    df['Date of Birth'] = pd.to_datetime(df['Date of Birth'], infer_datetime_format=True)\n",
    "    df['Gender'] = key[0]\n",
    "    df['Event'] = key[1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build data frame and export as csv file\n",
    "full_df = pd.concat([make_df(key) for key in urls])\n",
    "full_df.to_csv(r'Output/data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
